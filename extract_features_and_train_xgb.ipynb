{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d6398b8a82ec3d9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T14:26:42.424974Z",
     "start_time": "2025-09-26T14:26:41.182249Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\narges\\anaconda3\\envs\\rgc-features\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "execution_count": 12,
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install xgboost\n",
    "# !pip install tqdm\n",
    "#"
   ],
   "id": "251a3b2eab80c59f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T02:48:16.647888Z",
     "start_time": "2025-10-02T02:48:16.633311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dependencies: numpy, scipy, scikit-image, opencv-python, pywt, sklearn, torchvision, torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import greycomatrix, greycoprops, local_binary_pattern\n",
    "from skimage.filters import gabor\n",
    "from skimage.filters import laplace\n",
    "import pywt\n",
    "from scipy.stats import skew, kurtosis, entropy as shannon_entropy\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "from glob import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defenition",
   "id": "ae4093152a957bef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:45:15.884633Z",
     "start_time": "2025-10-02T02:45:15.509238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def basic_intensity_features(img):\n",
    "    p = np.percentile(img, [10,25,50,75,90])\n",
    "    hist = np.histogram(img, bins=256, range=(0,255))[0] + 1  # add 1 to avoid log(0)\n",
    "    return {\n",
    "        'mean': img.mean(),\n",
    "        'std': img.std(),\n",
    "        'skew': skew(img.ravel()),\n",
    "        'kurt': kurtosis(img.ravel()),\n",
    "        'p10': p[0], 'p25': p[1], 'p50': p[2], 'p75': p[3], 'p90': p[4],\n",
    "        'entropy': shannon_entropy(hist)\n",
    "    }\n",
    "\n",
    "def glcm_features(img, distances=[1,2,4], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    # convert to uint8 levels 0..255 then to e.g. 32 levels to reduce GLCM size\n",
    "    levels = 32\n",
    "    im = (img / (256/levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(im, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast','dissimilarity','homogeneity','energy','correlation','ASM']\n",
    "    feats = {}\n",
    "    # glcm = graycomatrix(img, distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "\n",
    "    for p in props:\n",
    "        # arr = greycoprops(glcm, p)\n",
    "        arr = graycoprops(glcm, p)\n",
    "\n",
    "        feats[p+'_mean'] = arr.mean()\n",
    "        feats[p+'_std'] = arr.std()\n",
    "    return feats\n",
    "\n",
    "def lbp_hist(img, P=8, R=1, bins=16):\n",
    "    im = img.astype(np.uint8)\n",
    "    lbp = local_binary_pattern(im, P, R, method='uniform')\n",
    "    (hist,_) = np.histogram(lbp.ravel(), bins=bins, range=(0, bins))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return {f'LBP_{i}': hist[i] for i in range(bins)}\n",
    "\n",
    "def gabor_features(img, frequencies=[0.1,0.2], thetas=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    feats = {}\n",
    "    for freq in frequencies:\n",
    "        for theta in thetas:\n",
    "            real, imag = gabor(img, frequency=freq, theta=theta)\n",
    "            mag = np.sqrt(real**2 + imag**2)\n",
    "            feats[f'gabor_f{freq}_t{theta}_mean'] = mag.mean()\n",
    "            feats[f'gabor_f{freq}_t{theta}_std'] = mag.std()\n",
    "    return feats\n",
    "\n",
    "def wavelet_energy(img, wavelet='db2', level=2):\n",
    "    coeffs = pywt.wavedec2(img.astype(float), wavelet=wavelet, level=level)\n",
    "    energies = {}\n",
    "    for i, arr in enumerate(coeffs[1:], start=1):\n",
    "        # arr is tuple (cH, cV, cD)\n",
    "        cH, cV, cD = arr\n",
    "        energies[f'wl_L{i}_cH'] = np.sum(cH**2)\n",
    "        energies[f'wl_L{i}_cV'] = np.sum(cV**2)\n",
    "        energies[f'wl_L{i}_cD'] = np.sum(cD**2)\n",
    "    return energies\n",
    "\n",
    "# Deep features (ResNet50 global pool)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# resnet = models.resnet50(pretrained=True)\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1]).to(device).eval()  # remove last fc\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def extract_deep(img):  # img: HxW uint8 gray or RGB\n",
    "    if img.ndim==2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "    x = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).cpu().numpy().reshape(-1)\n",
    "    return feat  # 2048-d\n"
   ],
   "id": "9e596fada74bd16b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:45:16.199068Z",
     "start_time": "2025-10-02T02:45:16.168936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skimage.filters import laplace, gaussian\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.feature import canny\n",
    "\n",
    "def extract_all_features_extended(img, use_deep=True):\n",
    "    \"\"\"\n",
    "    Extract all features (handcrafted + optional deep) from a single RGC image.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # --- 1. Basic intensity features ---\n",
    "    features.update(basic_intensity_features(img))\n",
    "\n",
    "    # --- 2. GLCM features ---\n",
    "    try:\n",
    "        features.update(glcm_features(img))\n",
    "    except Exception as e:\n",
    "        print(\"Warning: GLCM skipped:\", e)\n",
    "\n",
    "    # --- 3. LBP histogram ---\n",
    "    features.update(lbp_hist(img))\n",
    "\n",
    "    # --- 4. Gabor features ---\n",
    "    features.update(gabor_features(img))\n",
    "\n",
    "    # --- 5. Wavelet energies ---\n",
    "    features.update(wavelet_energy(img))\n",
    "\n",
    "    # --- 6. Edge density ---\n",
    "    edges = canny(img.astype(np.uint8))\n",
    "    features['edge_density'] = edges.mean()\n",
    "\n",
    "    # --- 7. LoG stats ---\n",
    "    log_img = laplace(gaussian(img, sigma=1))\n",
    "    features['LoG_mean'] = log_img.mean()\n",
    "    features['LoG_std'] = log_img.std()\n",
    "\n",
    "    # --- 8. Local entropy ---\n",
    "    try:\n",
    "        entropy_img = entropy(img.astype(np.uint8), disk(5))\n",
    "        features['local_entropy_mean'] = entropy_img.mean()\n",
    "        features['local_entropy_std'] = entropy_img.std()\n",
    "    except Exception as e:\n",
    "        print(\"Warning: Local entropy skipped:\", e)\n",
    "\n",
    "    # --- 9. Deep features ---\n",
    "    if use_deep:\n",
    "        try:\n",
    "            deep_feat = extract_deep(img)\n",
    "            features.update({f'deep_{i}': deep_feat[i] for i in range(len(deep_feat))})\n",
    "        except Exception as e:\n",
    "            print(\"Warning: Deep features skipped:\", e)\n",
    "\n",
    "    return features\n"
   ],
   "id": "1154b47859448a31",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test the feature extraction with one sample",
   "id": "b140dc519b5bd70a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T14:20:26.557533Z",
     "start_time": "2025-09-26T14:20:18.955639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "img_add=\"./Dataset/train/dic/1ld1.png\"\n",
    "img = cv2.imread(img_add, cv2.IMREAD_GRAYSCALE)\n",
    "img = img.astype(np.float64)\n",
    "\n",
    "feats = extract_all_features_extended(img, use_deep=True)  # False if you skip PyTorch\n",
    "\n",
    "# Convert to DataFrame for RF/XGBoost\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([feats])\n"
   ],
   "id": "b67a32147c767cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T14:20:26.573054Z",
     "start_time": "2025-09-26T14:20:26.562159Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "b5ed9278c99ff459",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         mean        std      skew      kurt    p10    p25    p50    p75  \\\n",
       "0  155.208651  12.350875  1.136561  2.078124  141.0  146.0  153.0  162.0   \n",
       "\n",
       "     p90   entropy  ...  deep_2038  deep_2039  deep_2040  deep_2041  \\\n",
       "0  171.0  3.790159  ...   0.006279   0.010693    0.00583   0.246146   \n",
       "\n",
       "   deep_2042  deep_2043  deep_2044  deep_2045  deep_2046  deep_2047  \n",
       "0   0.364183   0.144402   0.196051   0.289868        0.0   1.297428  \n",
       "\n",
       "[1 rows x 2113 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>p10</th>\n",
       "      <th>p25</th>\n",
       "      <th>p50</th>\n",
       "      <th>p75</th>\n",
       "      <th>p90</th>\n",
       "      <th>entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>deep_2038</th>\n",
       "      <th>deep_2039</th>\n",
       "      <th>deep_2040</th>\n",
       "      <th>deep_2041</th>\n",
       "      <th>deep_2042</th>\n",
       "      <th>deep_2043</th>\n",
       "      <th>deep_2044</th>\n",
       "      <th>deep_2045</th>\n",
       "      <th>deep_2046</th>\n",
       "      <th>deep_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.208651</td>\n",
       "      <td>12.350875</td>\n",
       "      <td>1.136561</td>\n",
       "      <td>2.078124</td>\n",
       "      <td>141.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3.790159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.00583</td>\n",
       "      <td>0.246146</td>\n",
       "      <td>0.364183</td>\n",
       "      <td>0.144402</td>\n",
       "      <td>0.196051</td>\n",
       "      <td>0.289868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.297428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2113 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the Dataset feature maps",
   "id": "2c8a06aec6ff7dd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract features - it takes too long :(\n",
   "id": "8ee3164a3b5732a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "train_dic=\"./Dataset/train/dic/*.png\"\n",
    "image_files = glob(train_dic)  # or .jpg\n",
    "all_features = []\n",
    "\n",
    "for file in image_files:\n",
    "    print(file)\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img.astype(np.float64)\n",
    "\n",
    "    feats = extract_all_features_extended(img, use_deep=True)  # or True\n",
    "\n",
    "    feats['filename'] = file\n",
    "    all_features.append(feats)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_features)\n",
    "df.fillna(0, inplace=True)  # replace any missing values with 0\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"./Feature_maps/train_rgc_features_f64.csv\", index=False)"
   ],
   "id": "d27aa854ca90fa5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract features using concurrent workers",
   "id": "ff0824a0035d6277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image(file):\n",
    "    \"\"\"Process one image and extract features.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float64)\n",
    "\n",
    "        feats = extract_all_features_extended(img, use_deep=True)\n",
    "        feats['filename'] = file\n",
    "        return feats\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# image folder\n",
    "sets= ['train' , 'test' , 'eval']\n",
    "for set in sets:\n",
    "    folder_dic = \"./Dataset/\"+ set +\"/dic/*.png\"\n",
    "    image_files = glob(folder_dic)\n",
    "    # Use tqdm to wrap the iterable\n",
    "    results = Parallel(n_jobs=8, backend='threading')(\n",
    "        delayed(process_image)(file) for file in tqdm(image_files, desc=\"Extracting features\")\n",
    "    )\n",
    "\n",
    "    # Filter out None results\n",
    "    all_features = [f for f in results if f is not None]\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.to_csv(\"./Feature_maps/\"+ set +\"_rgc_features_f64.csv\", index=False)\n",
    "\n",
    "    print(\"✅ Feature extraction complete. Saved to \"+ set +\"_rgc_features_f64.csv\")\n"
   ],
   "id": "19bbbd6519289f9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the label Column based on the manual cell counts:",
   "id": "c0d9b4c5b9664ef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T15:09:04.681622Z",
     "start_time": "2025-10-13T15:09:04.668117Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # other ways of labeling the dataset\n",
    " # you can edit the margin of splitting the classes\n",
    " # 400–500 cells ==> central\n",
    " # 350–430 cells ==> middle\n",
    " # 250–300 cells ==> periphery\n",
    " #\n",
    "# # Define expected ranges and their midpoints\n",
    "# region_midpoints = {\n",
    "#     \"central\":   np.mean([400, 500]),   # 450\n",
    "#     \"middle\":    np.mean([350, 430]),   # 390\n",
    "#     \"periphery\": np.mean([250, 300])    # 275\n",
    "# }\n",
    "#\n",
    "# def assign_region(auto_count):\n",
    "#     diffs = {region: abs(auto_count - mid) for region, mid in region_midpoints.items()}\n",
    "#     return min(diffs, key=diffs.get)\n",
    "\n",
    "\n",
    "# def assign_region(auto_count):\n",
    "#     if 400 <= auto_count :\n",
    "#         return \"central\"\n",
    "#     elif 280 < auto_count < 400:\n",
    "#         return \"middle\"\n",
    "#     elif  auto_count <= 280:\n",
    "#         return \"periphery\"\n",
    "#     else:\n",
    "#         return \"unknown\"\n"
   ],
   "id": "f297b6386fc14422",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:09.055579Z",
     "start_time": "2025-10-02T02:54:09.041069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_region(auto_count):\n",
    "    if  auto_count <=300 :\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return \"moderate\"\n"
   ],
   "id": "50dc1df86caf40d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:11.615867Z",
     "start_time": "2025-10-02T02:54:11.600868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels_df = pd.read_csv(\"./Dataset/manaull_counts.csv\")  # make sure path is correct\n",
    "labels_df[\"region\"] = labels_df[\"manual count\"].apply(assign_region)\n",
    "labels_df.rename(columns={\"file name\": \"filename\"}, inplace=True)"
   ],
   "id": "39bade7cf89d5d50",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:13.083979Z",
     "start_time": "2025-10-02T02:54:12.131122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset=['train' , 'test' , 'eval']\n",
    "for i in dataset:\n",
    "    features_df =pd.read_csv('./Feature_maps/'+i+'_rgc_features_f64.csv') # after extraction loop\n",
    "    features_df.fillna(0, inplace=True)\n",
    "    features_df['filename'] = features_df['filename'].str.split(\"\\\\\").str[-1]\n",
    "    features_df['filename'] = features_df['filename'].str.split(\".\").str[0]\n",
    "    final_df = pd.merge(features_df, labels_df, on=\"filename\", how=\"inner\")\n",
    "    final_df.to_csv(\"./Feature_maps/\"+ i+\"_features_with_labels_f64_with_lables.csv\", index=False)\n",
    "\n"
   ],
   "id": "9297eb6418b419c1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Start Training\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load data\n",
    "# -------------------------------"
   ],
   "id": "58c3b1bd94f89469"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "train_df = pd.read_csv(\"./train_features_with_labels_f64_with_lables.csv\")\n",
    "test_df  = pd.read_csv(\"./test_features_with_labels_f64_with_lables.csv\")\n",
    "\n",
    "# Drop filename column (not useful for training)\n",
    "X_train = train_df.drop(columns=[\"filename\", \"region\" , \"manual count\",\t\"auto count\"])\n",
    "y_train = train_df[\"region\"]\n",
    "\n",
    "X_test  = test_df.drop(columns=[\"filename\", \"region\" , \"manual count\",\t\"auto count\"])\n",
    "y_test  = test_df[\"region\"]\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ],
   "id": "51c7544df9335f4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:20.358757Z",
     "start_time": "2025-10-02T02:54:19.873644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Replace inf and -inf with NaN\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill NaNs with column means (or 0 if you prefer)\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_test  = X_test.fillna(X_train.mean())  # use train mean for consistency\n",
    "\n",
    "# Optional: convert to float32 if very large numbers exist\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test  = X_test.astype(np.float32)\n"
   ],
   "id": "4577b9f76a463205",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 2. Random Forest baseline\n",
    "# -------------------------------"
   ],
   "id": "a82f7b11ffb372ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:51:20.629151Z",
     "start_time": "2025-10-02T02:51:20.186901Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "[[ 41   7]\n",
      " [  5 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low      0.891     0.854     0.872        48\n",
      "    moderate      0.936     0.954     0.945       108\n",
      "\n",
      "    accuracy                          0.923       156\n",
      "   macro avg      0.914     0.904     0.909       156\n",
      "weighted avg      0.922     0.923     0.923       156\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23,
   "source": [
    "\n",
    "print(\"🔹 Training Random Forest...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf, digits=3))"
   ],
   "id": "8120820e1f39ed1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 3. XGBoost (usually stronger)\n",
    "# -------------------------------"
   ],
   "id": "1b072e313b7475f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:29.341010Z",
     "start_time": "2025-10-02T02:54:29.326725Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 32,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)  # e.g. central->0, middle->1, periphery->2\n",
    "y_test_enc  = le.transform(y_test)       # use same encoder\n"
   ],
   "id": "fa9aaef41374504b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:54:38.775643Z",
     "start_time": "2025-10-02T02:54:30.059813Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Training XGBoost...\n",
      "\n",
      "XGBoost Re       sults:\n",
      "[[53  4]\n",
      " [ 3 96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low      0.946     0.930     0.938        57\n",
      "    moderate      0.960     0.970     0.965        99\n",
      "\n",
      "    accuracy                          0.955       156\n",
      "   macro avg      0.953     0.950     0.951       156\n",
      "weighted avg      0.955     0.955     0.955       156\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33,
   "source": [
    "\n",
    "print(\"\\n🔹 Training XGBoost...\")\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train_enc)\n",
    "\n",
    "y_pred_enc = xgb_clf.predict(X_test)\n",
    "\n",
    "# Convert back to original labels if needed\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "\n",
    "print(\"\\nXGBoost Re       sults:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ],
   "id": "ffac8e23abe21d3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T02:55:01.317981Z",
     "start_time": "2025-10-02T02:55:01.288118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Save the model\n",
    "xgb_clf.save_model(\"./checkpoints/xgb_regions_detection_model.json\")  # or .bin"
   ],
   "id": "3690ac8d7759e226",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use the saved model",
   "id": "a6c8c6680dd1217b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Later, load the model\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model(\"xgb_regions_detection_model.json\")\n",
    "print(y_test[:5])\n",
    "\n",
    "# Predict with it\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(y_pred[:5])\n",
    "\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "print(y_pred[:5])"
   ],
   "id": "2c076fd137b51bc8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.feature import peak_local_max\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%run generator.ipynb\n",
    "%run model.ipynb\n",
    "# import xgboost as xgb\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from google.colab.patches import cv2_imshow  # Only required in Google Colab\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"imageio\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Definitions",
   "id": "ac72a8ad817b3d09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def detect_cells_a1(density_map, sigma=2, threshold_factor=1.5):\n",
    "    # Smooth the density map using a Gaussian filter\n",
    "    smoothed_map = gaussian_filter(density_map, sigma=sigma)\n",
    "\n",
    "    # Calculate threshold based on the mean and standard deviation of the smoothed map\n",
    "    mean_val = np.mean(smoothed_map)\n",
    "    std_val = np.std(smoothed_map)\n",
    "    threshold = mean_val + threshold_factor * std_val\n",
    "    # Identify local maxima above the threshold\n",
    "    coordinates = peak_local_max(smoothed_map, min_distance=2, threshold_abs=threshold)\n",
    "\n",
    "    # Convert to a list of (x, y) tuples\n",
    "    cell_centroids = [(int(x), int(y)) for y, x in coordinates]\n",
    "\n",
    "    return cell_centroids\n",
    "\n",
    "\n",
    "def detect_cells_a2_1(density_map, sigma=2, threshold_factor=1.5):\n",
    "    # Convert input to numpy if needed\n",
    "    if not isinstance(density_map, np.ndarray):\n",
    "        density_map = np.array(density_map)\n",
    "\n",
    "    # Handle various input types\n",
    "    if density_map.ndim == 3:  # Color image\n",
    "        density_map = density_map.mean(axis=2)  # Convert to grayscale\n",
    "\n",
    "    # Normalize to 0-1 range\n",
    "    density_map = density_map.astype(np.float32)\n",
    "\n",
    "    # Normalize to [0, 1] float\n",
    "    img_norm = cv2.normalize(density_map, None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Threshold the image to get binary mask of bright regions\n",
    "    _, binary_mask = cv2.threshold(img_norm, 0.7, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Processing pipeline\n",
    "    smoothed = gaussian_filter(density_map, sigma=sigma)\n",
    "    threshold = np.mean(smoothed) + threshold_factor * np.std(smoothed)\n",
    "    # Suppose 'image' is your grayscale image\n",
    "\n",
    "    coords = peak_local_max(smoothed,\n",
    "                            min_distance=2,\n",
    "                            threshold_abs=threshold,\n",
    "                            exclude_border=False,\n",
    "                            num_peaks=1000)\n",
    "    # print('before------' , len(coords))\n",
    "    if len(coords) != 1000:\n",
    "        return [(int(x), int(y)) for y, x in coords]\n",
    "    else:\n",
    "        return []\n"
   ],
   "id": "d91eb2252a054fb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def draw_cell_detections(image, centroids, radius=15, color=(255, 0, 0), thickness=2):\n",
    "    \"\"\"Draw circles around detected cells on the image.\"\"\"\n",
    "    vis_image = image.copy()\n",
    "    if len(vis_image.shape) == 2:  # Convert grayscale to color for visualization\n",
    "        vis_image = cv2.cvtColor(vis_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for (x, y) in centroids:\n",
    "        cv2.circle(vis_image, (int(x), int(y)), radius, color, thickness)\n",
    "    return vis_image\n",
    "\n",
    "\n",
    "def draw_cell_detections_filterd(image, filtred_centroids, non_filtred_centroids, radius=10, color=(255, 0, 0),\n",
    "                                 thickness=2):\n",
    "    \"\"\"Draw circles around detected cells on the image.\"\"\"\n",
    "    vis_image = image.copy()\n",
    "    if len(vis_image.shape) == 2:  # Convert grayscale to color for visualization\n",
    "        vis_image = cv2.cvtColor(vis_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for (x, y) in non_filtred_centroids:\n",
    "        cv2.circle(vis_image, (int(x), int(y)), radius, color, thickness)\n",
    "    for (x, y) in filtred_centroids:\n",
    "        cv2.circle(vis_image, (int(x), int(y)), radius, (0, 0, 255), thickness)\n",
    "    return vis_image\n",
    "\n",
    "\n",
    "def draw_grids(draw_grid, X, Y, tile_size, save_folder, gt_visualization, rec_visualization, animal_name,\n",
    "               enhanced=False):\n",
    "    if draw_grid:\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            cv2.rectangle(rec_visualization, (x, y), (x + tile_size, y + tile_size), (0, 255, 0), 1)\n",
    "            cv2.putText(rec_visualization, f\"{x},{y}\", (x + 5, y + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            cv2.rectangle(gt_visualization, (x, y), (x + tile_size, y + tile_size), (0, 255, 0), 1)\n",
    "            cv2.putText(gt_visualization, f\"{x},{y}\", (x + 5, y + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Save visualizations\n",
    "    cv2.imwrite(os.path.join(save_folder, f\"{animal_name}_1_gt_detections.png\"), gt_visualization)\n",
    "    rec_visualization_cropped = rec_visualization[3:-3, 3:-3]\n",
    "    if enhanced:\n",
    "        cv2.imwrite(os.path.join(save_folder, f\"{animal_name}_3_rec_detections.png\"), rec_visualization_cropped)\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(save_folder, f\"{animal_name}_2_rec_detections.png\"), rec_visualization_cropped)\n",
    "\n",
    "    print(f\"Visualizations with detected cells saved to {save_folder}\")\n",
    "\n",
    "\n",
    "def search_in_csv(animal_name, csv_file):\n",
    "    file_path = csv_file\n",
    "\n",
    "    # Search term (you can also hard-code this)\n",
    "    search_term = animal_name\n",
    "    df = pd.read_csv(file_path)\n",
    "    matching_rows = df[df.iloc[:, 0].astype(str).str.strip() == search_term]\n",
    "    if not matching_rows.empty:\n",
    "        return matching_rows\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_results_csv(save_folder, manual_count_file, animal_name, gt_cell_centroids, rec_cell_centroids,\n",
    "                     rec_cell_centroids_e, network_type ,dataset , xgb_pred):\n",
    "    csv_path = os.path.join(save_folder, dataset + \"_cell_counts.csv\")\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "    row_manual_count = search_in_csv(animal_name, manual_count_file)\n",
    "    # print(animal_name , row_manual_count)\n",
    "    print(\"Manual GT cells: \", row_manual_count.iloc[0, 1], \"\\nAuto Ground truth cells _ method 1:\",\n",
    "          row_manual_count.iloc[0, 2], \"\\nAuto Ground truth cells _ method 2 :\", len(gt_cell_centroids),\n",
    "          \"\\nReconstructed cells:\", len(rec_cell_centroids), \"\\nremoved overlapped cells:\", len(rec_cell_centroids_e))\n",
    "    # print(\"Pixel value range - min:\", np.min(reconstructed), \"max:\", np.max(reconstructed))\n",
    "\n",
    "    with open(csv_path, mode='a', newline='') as csv_file:\n",
    "        fieldnames = ['Animal Name', 'Network Type', 'Manual GT Cells', 'Auto method GT Cells method 1 ',\n",
    "                      'Auto method GT Cells method 2 ', 'Reconstructed Cells', 'Difference (gt- pred)',\n",
    "                      'Abs Difference', 'Error rate', 'Abs Error rate', 'removed overlapped cells',\n",
    "                      'Difference (gt- pred_e)', 'Abs Difference enh', 'Error rate enh', 'Abs Error rate enh']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow({\n",
    "            'Animal Name': animal_name,\n",
    "            'Network Type': network_type +\" \" +xgb_pred,\n",
    "            'Manual GT Cells': row_manual_count.iloc[0, 1],\n",
    "            'Auto method GT Cells method 1 ': row_manual_count.iloc[0, 2],\n",
    "            'Auto method GT Cells method 2 ': len(gt_cell_centroids),\n",
    "            'Reconstructed Cells': len(rec_cell_centroids),\n",
    "            'Difference (gt- pred)': len(gt_cell_centroids) - len(rec_cell_centroids),\n",
    "            'Abs Difference': math.fabs(len(gt_cell_centroids) - len(rec_cell_centroids)),\n",
    "            'Error rate': (len(gt_cell_centroids) - len(rec_cell_centroids)) / len(gt_cell_centroids) * 100,\n",
    "            'Abs Error rate': math.fabs(len(gt_cell_centroids) - len(rec_cell_centroids)) / len(\n",
    "                gt_cell_centroids) * 100,\n",
    "\n",
    "            'removed overlapped cells': len(rec_cell_centroids_e),\n",
    "            'Difference (gt- pred_e)': len(gt_cell_centroids) - len(rec_cell_centroids_e),\n",
    "            'Abs Difference enh': math.fabs(len(gt_cell_centroids) - len(rec_cell_centroids_e)),\n",
    "            'Error rate enh': (len(gt_cell_centroids) - len(rec_cell_centroids_e)) / len(gt_cell_centroids) * 100,\n",
    "            'Abs Error rate enh': math.fabs(len(gt_cell_centroids) - len(rec_cell_centroids_e)) / len(\n",
    "                gt_cell_centroids) * 100,\n",
    "        })\n",
    "\n",
    "\n",
    "def extract_main_name(filename):\n",
    "    parts = filename.split('.')\n",
    "\n",
    "    return parts[0]  # If no tile index found\n",
    "\n",
    "\n",
    "def main_name_ends_with_1(filename):\n",
    "    main_name = extract_main_name(filename)\n",
    "    return main_name is not None and main_name.endswith('1')\n",
    "\n",
    "\n",
    "def merge_overlapping_cells_keep_others(centroids, radius=15):\n",
    "    centroids = np.array(centroids, dtype=float)\n",
    "    visited = np.zeros(len(centroids), dtype=bool)\n",
    "    merged_centroids = []\n",
    "\n",
    "    for i in range(len(centroids)):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "\n",
    "        # Find all centroids overlapping with this one\n",
    "        cluster = [centroids[i]]\n",
    "        visited[i] = True\n",
    "\n",
    "        for j in range(i + 1, len(centroids)):\n",
    "            if visited[j]:\n",
    "                continue\n",
    "            dist = np.linalg.norm(centroids[i] - centroids[j])\n",
    "            if dist < 2 * radius:  # Overlap threshold\n",
    "                cluster.append(centroids[j])\n",
    "                visited[j] = True\n",
    "\n",
    "        if len(cluster) == 1:\n",
    "            # No overlaps → keep as is\n",
    "            merged_centroids.append(tuple(cluster[0]))\n",
    "        else:\n",
    "            # Merge cluster → take average\n",
    "            cluster_center = np.mean(cluster, axis=0)\n",
    "            merged_centroids.append(tuple(cluster_center))\n",
    "\n",
    "    return merged_centroids\n"
   ],
   "id": "59399b5d4d972342",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Reconstruct cells\n",
    "def reconstruct_image_from_tiles(dataset , network_type,xgb_pred, manual_count_file, tile_folder, save_folder,  animal_name, label_image_add, file_names_saved, dic_image, sigma=5.5, threshold=2,\n",
    "                                 m_color=(255, 0, 0), draw_grid=True , force_save=False):\n",
    "    final_size = 1406\n",
    "    tile_size = 256\n",
    "    label_image = cv2.imread(label_image_add)\n",
    "    label_image = cv2.cvtColor(label_image, cv2.COLOR_BGR2GRAY)\n",
    "    X, Y, reconstructed = reconstruct(tile_folder, file_names_saved, animal_name, final_size, tile_size)\n",
    "    # # print(len(X) , len(Y) , X , Y )\n",
    "    rec_cell_centroids = detect_cells_a2_1(reconstructed, sigma=sigma, threshold_factor=threshold)\n",
    "    gt_cell_centroids = detect_cells_a1(label_image, sigma=2.5, threshold_factor=1.5)\n",
    "\n",
    "    gt_visualization = draw_cell_detections(label_image, gt_cell_centroids)\n",
    "    rec_cell_centroids_aftre_removing_overlaps = merge_overlapping_cells_keep_others(rec_cell_centroids, radius=15)\n",
    "    # rec_visualization = draw_cell_detections(reconstructed, rec_cell_centroids_aftre_removing_overlaps)\n",
    "    rec_visualization = draw_cell_detections(dic_image, rec_cell_centroids_aftre_removing_overlaps, color=m_color)\n",
    "\n",
    "    print(\"Gt cell counts: \", len(gt_cell_centroids))\n",
    "    print(\"Predicted cell counts:  \", len(rec_cell_centroids))\n",
    "    print(\"Predicted cell counts after removing overlaps:  \", len(rec_cell_centroids_aftre_removing_overlaps))\n",
    "\n",
    "    # Draw grid if needed\n",
    "\n",
    "    # Save cell counts to CSV\n",
    "    draw_grids(draw_grid, X, Y, tile_size, save_folder, gt_visualization, rec_visualization, animal_name,\n",
    "               enhanced=False)\n",
    "    if len(rec_cell_centroids_aftre_removing_overlaps)==0  and force_save:\n",
    "        print(\"here  saving \" , str(xgb_pred))\n",
    "        save_results_csv( save_folder, manual_count_file, animal_name, gt_cell_centroids, rec_cell_centroids,\n",
    "                     rec_cell_centroids_aftre_removing_overlaps, network_type  , dataset ,\" xgb \"+ str(xgb_pred))\n",
    "\n",
    "    if len(rec_cell_centroids_aftre_removing_overlaps)==0:\n",
    "        print(\"here not saving\")\n",
    "        return reconstructed, rec_visualization , len(rec_cell_centroids_aftre_removing_overlaps)\n",
    "\n",
    "    else:\n",
    "        print(\"here  saving \" , str(xgb_pred))\n",
    "        save_results_csv( save_folder, manual_count_file, animal_name, gt_cell_centroids, rec_cell_centroids,\n",
    "                     rec_cell_centroids_aftre_removing_overlaps, network_type  , dataset ,\" xgb \"+ str(xgb_pred))\n",
    "    return reconstructed, rec_visualization , rec_cell_centroids_aftre_removing_overlaps\n"
   ],
   "id": "856139d30c7bb98f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def reconstruct(tile_folder, file_names_saved, animal_name, final_size, tile_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    reconstructed = np.zeros((final_size, final_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # Regex to extract x, y from filenames\n",
    "    pattern = re.compile(f\"{animal_name}_\\d+_x(\\d+)_y(\\d+)\\.png\")\n",
    "\n",
    "    # First pass: Load all tiles and their positions\n",
    "    tiles = []\n",
    "    for filename in os.listdir(tile_folder):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            x = int(match.group(1))\n",
    "            y = int(match.group(2))\n",
    "            tile_path = os.path.join(tile_folder, filename, file_names_saved)\n",
    "            # print('tile path is',tile_path)\n",
    "            tile_img = cv2.imread(tile_path)\n",
    "            # if tile_img is not None and tile_img.std()< 10:\n",
    "            #     # tile_img  = np.zeros(tile_img.shape, dtype=np.uint8)\n",
    "            #     tile_img = np.ones(tile_img.shape, dtype=np.uint8) * 255  # all pixels = 255 (white)\n",
    "\n",
    "            # Copy image (preserves metadata)\n",
    "            # shutil.copy(tile_path, os.path.join(save_folder, str(filename)))\n",
    "            if tile_img is not None:\n",
    "                tiles.append((x, y, tile_img))\n",
    "            else:\n",
    "                print(f\"Warning: Couldn't load {tile_path}, skipping.\")\n",
    "\n",
    "    # 1.reconstruct images:\n",
    "    # 2.merge overlaps\n",
    "    # 3.save the location of cells of each tile after merging\n",
    "    for x, y, tile_pred in sorted(tiles, key=lambda item: (-item[0], -item[1])):\n",
    "\n",
    "        current_region = reconstructed[y:y + tile_size, x:x + tile_size]\n",
    "\n",
    "        tile_gray = cv2.cvtColor(tile_pred, cv2.COLOR_BGR2GRAY)\n",
    "        current_gray = cv2.cvtColor(current_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        mask = tile_gray > current_gray\n",
    "        for c in range(3):\n",
    "            reconstructed[y:y + tile_size, x:x + tile_size, c] = np.where(\n",
    "                mask,\n",
    "                tile_pred[:, :, c],\n",
    "                current_region[:, :, c]\n",
    "            )\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y, reconstructed\n"
   ],
   "id": "da999361b02954c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_xgb_results(animal_name, saved_add, set_name):\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Load data\n",
    "    # -------------------------------\n",
    "\n",
    "    df = pd.read_csv(saved_add + set_name+ \"/\"+set_name+\"_features_with_labels_f64.csv\")\n",
    "    row = df[df['filename'] == animal_name]\n",
    "    # Drop filename column (not useful for training)\n",
    "    X  = row.drop(columns=[\"filename\", \"region\" , \"manual count\",\t\"auto count\"])\n",
    "    y  = row[\"region\"]\n",
    "    print(\"y is ----\",y)\n",
    "    return X, y"
   ],
   "id": "a1d7580d5ea42f28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final Workflow - XGB_UNetFuse",
   "id": "d01cda707bb6702c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "saved_add = './Dataset/'\n",
    "manual_count_file = './Dataset/match_auto_and_manaull_counts_corrected_high_discrepancy.csv'\n",
    "\n",
    "# for both train and test\n",
    "address = ['train', 'test', 'eval']\n",
    "for i in range(len(address)):\n",
    "\n",
    "    all_animals = sorted([\n",
    "        f for f in os.listdir(saved_add + address[i] + '/dic/')\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))\n",
    "    ])\n",
    "    # print(all_animals)\n",
    "\n",
    "    tiles_predicted_light_unet = './results/Light_U_Net/' + address[\n",
    "        i] + '_outputs_light_u_net_256/'\n",
    "    tiles_predicted_unet = './results/U_Net/' + address[i] + '_outputs_u_net_256/'\n",
    "    save_dir = './results/XGB_UNetFuse/' + address[i] + '_workflow/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for animal_name in all_animals:\n",
    "        # if animal_name.split('.')[0] != '':\n",
    "        animal_name = animal_name.split('.')[0]\n",
    "        original_image_add = saved_add + address[i] + '/dic/' + animal_name + '.png'\n",
    "        if address[i] != 'eval':\n",
    "            label_image_add = saved_add + address[i] + '/gt/' + animal_name + '.png'\n",
    "        else:\n",
    "            label_image_add = saved_add + address[i] + '/dic/' + animal_name + '.png'\n",
    "        dic_image = cv2.imread(original_image_add)\n",
    "        print(label_image_add)\n",
    "        # animal_name= '31_8_rd1'\n",
    "        X, y = get_xgb_results(animal_name, saved_add, address[i])\n",
    "        loaded_model = xgb.XGBClassifier()\n",
    "        loaded_model.load_model(saved_add + \"xgb_regions_detection_model.json\")\n",
    "        # Predict with it\n",
    "        y_pred = loaded_model.predict(X)\n",
    "        print(animal_name, y , \"---- y prediction -----\",y_pred )\n",
    "        #\n",
    "\n",
    "        if y_pred ==2: # its preph\n",
    "            r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] , \"Light-U-Net_55_1\",  y_pred , manual_count_file,       tiles_predicted_light_unet, save_dir,\n",
    "            animal_name, label_image_add, 'image_pr_regions.jpg', dic_image, sigma=5.5,\n",
    "            threshold=1, m_color=(255, 0, 0))\n",
    "\n",
    "            if len(cell_counts)< 5:\n",
    "                r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] , \"Light-U-Net_55_075\",  y_pred , manual_count_file,       tiles_predicted_light_unet, save_dir,\n",
    "                animal_name, label_image_add, 'image_pr_regions.jpg', dic_image, sigma=5.5,\n",
    "                threshold=0.75, m_color=(255, 0, 0))\n",
    "\n",
    "        else : # its central or middle\n",
    "\n",
    "            r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] ,\"U-Net_55_05\", y_pred,manual_count_file, tiles_predicted_unet,\n",
    "            save_dir, animal_name, label_image_add,\n",
    "            'image_pr_regions.jpg', dic_image, sigma=5.5, threshold=0.5, m_color=(0, 255, 0))\n",
    "            if len(cell_counts) < 50:\n",
    "                r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] ,\"U-Net_55_075\", y_pred, manual_count_file, tiles_predicted_unet,\n",
    "                save_dir, animal_name, label_image_add,\n",
    "                'image_pr_regions.jpg', dic_image, sigma=5.5, threshold=0.75,\n",
    "                m_color=(0, 0, 255))\n",
    "                if len(cell_counts)< 350:\n",
    "                    r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] , \"Light-U-Net_55_1\",  y_pred, manual_count_file,       tiles_predicted_light_unet, save_dir,\n",
    "                    animal_name, label_image_add, 'image_pr_regions.jpg', dic_image, sigma=5.5,\n",
    "                    threshold=1, m_color=(255, 0, 0) , force_save= True)\n",
    "\n",
    "\n",
    "\n",
    "    #     break\n",
    "    # break\n"
   ],
   "id": "de57f21390cd054"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reconstruction of Light_U_Net and U_Net results",
   "id": "2f6e6b7f2b0575cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " You can try plotting the results of Light_U_Net and U_Net with diffrent combinations of T and sigma.",
   "id": "86566038d89008c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "saved_add = './Dataset/'\n",
    "manual_count_file = './Dataset/match_auto_and_manaull_counts_corrected_high_discrepancy.csv'\n",
    "\n",
    "# for both train and test\n",
    "address = [ 'train' , 'test' , 'eval']\n",
    "for i in range(len(address)):\n",
    "\n",
    "    all_animals = sorted([\n",
    "        f for f in os.listdir(saved_add + address[i] + '/dic/')\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))\n",
    "    ])\n",
    "    # print(all_animals)\n",
    "\n",
    "    tiles_predicted_light_unet = 'C:/Users/narges/PycharmProjects3/full_size_data_training/results/Paper_figures/Light_U_Net_bigger_regions/' + address[\n",
    "        i] + '_outputs_light_u_net_256/'\n",
    "    tiles_predicted_unet = 'C:/Users/narges/PycharmProjects3/full_size_data_training/results/Paper_figures/U_Net/' + address[i] + '_outputs_u_net_256/'\n",
    "    light_save_dir = './results/Light_U_Net/' + address[i] + '_reconstructed_outputs_light_u_net_256_55_1/'\n",
    "    unet_save_dir = './results/U_Net/' + address[i] + '_reconstructed_outputs_u_net_256_55_05/'\n",
    "    os.makedirs(light_save_dir, exist_ok=True)\n",
    "    os.makedirs(unet_save_dir, exist_ok=True)\n",
    "    for animal_name in all_animals:\n",
    "        # if animal_name.split('.')[0] != '':\n",
    "        animal_name = animal_name.split('.')[0]\n",
    "        original_image_add = saved_add + address[i] + '/dic/' + animal_name + '.png'\n",
    "        if address[i] != 'eval':\n",
    "            label_image_add = saved_add + address[i] + '/gt/' + animal_name + '.png'\n",
    "        else:\n",
    "            label_image_add = saved_add + address[i] + '/dic/' + animal_name + '.png'\n",
    "\n",
    "        dic_image = cv2.imread(original_image_add)\n",
    "\n",
    "        r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] , \"Light-U-Net_55_1\",  \"\" , manual_count_file,       tiles_predicted_light_unet, light_save_dir,\n",
    "        animal_name, label_image_add, 'image_pr_regions.jpg', dic_image, sigma=5.5,\n",
    "        threshold=1, m_color=(255, 0, 0))\n",
    "\n",
    "        r, rec_visualization  , cell_counts = reconstruct_image_from_tiles(address[i] ,\"U-Net_55_05\", \"\",manual_count_file, tiles_predicted_unet,\n",
    "        unet_save_dir, animal_name, label_image_add,\n",
    "        'image_pr_regions.jpg', dic_image, sigma=5.5, threshold=0.5, m_color=(0, 255, 0))\n",
    "\n",
    "    #     break\n",
    "    # break\n"
   ],
   "id": "54fce3b3c073b6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c52cd83a37a43a72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

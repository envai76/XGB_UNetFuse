{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "77c301f30984b64e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.ndimage import gaussian_filter, label\n",
    "from skimage.feature import peak_local_max\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%run generator.ipynb\n",
    "%run model.ipynb\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"imageio\")\n",
    "# from google.colab.patches import cv2_imshow  # Only required in Google Colab\n"
   ],
   "id": "402013387aa1a35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# List available physical devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\")\n",
    "for device in physical_devices:\n",
    "    print(device)\n",
    "\n",
    "# Check if TensorFlow is using the GPU\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"TensorFlow is built with CUDA\")\n",
    "    if len(physical_devices) > 0:\n",
    "        print(\"TensorFlow is using the GPU\")\n",
    "    else:\n",
    "        print(\"TensorFlow is not using the GPU, but it is available\")\n",
    "else:\n",
    "    print(\"TensorFlow is not built with CUDA\")\n",
    "\n"
   ],
   "id": "9f5ce64e0b1cdb9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions",
   "id": "c702b4a345f8cf63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def extract_main_name(self ,filename):\n",
    "        parts = filename.split('_')\n",
    "        for i, part in enumerate(parts):\n",
    "            if re.fullmatch(r'\\d{3}', part):  # Find the first 3-digit part\n",
    "                return '_'.join(parts[:i])    # Main name is everything before that\n",
    "        return None  # If no tile index found\n",
    "\n",
    "    def main_name_ends_with_1(self , filename):\n",
    "        main_name = self.extract_main_name(filename)\n",
    "        return main_name is not None and main_name.endswith('1')\n",
    "\n",
    "    def __init__(self, data_dir, label_dir , label_dir_regions, batch_size, dim, n_channels=1, n_classes_or_output_dim=1 , shuffle=True, augmentor=None ):\n",
    "        'Initialization'\n",
    "        self.dim = dim  # e.g., (256, 256)\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir  # Directory containing input images\n",
    "        self.label_dir = label_dir  # Directory containing label images\n",
    "        self.label_dir_regions = label_dir_regions\n",
    "        self.n_channels = n_channels  # Will be 1 for grayscale\n",
    "        self.n_classes_or_output_dim = n_classes_or_output_dim  # e.g., 1 for regression output\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentor = augmentor  # Your ImageDataGenerator instance\n",
    "        self.target_size=self.dim[0]\n",
    "        self.filtered_filenames = sorted([\n",
    "            f for f in os.listdir(self.data_dir)\n",
    "            if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))# and self.main_name_ends_with_1(f)\n",
    "             ])\n",
    "\n",
    "\n",
    "        self.data_files = [os.path.join(data_dir, f) for f in self.filtered_filenames]\n",
    "        self.label_files = [os.path.join(label_dir, f) for f in self.filtered_filenames]\n",
    "        self.label_regions_files = [os.path.join(label_dir_regions, f) for f in self.filtered_filenames]\n",
    "\n",
    "        # Get list of all image files in the directories\n",
    "        # self.data_files = [os.path.join(data_dir, f) for f in self.filtered_filenames]\n",
    "        #                     self.filtered_filenames = sorted([ f for f in os.listdir(data_dir)\n",
    "        #                     if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')) and self.main_name_ends_with_1(f) ])\n",
    "\n",
    "        # self.data_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
    "        #                         if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))])\n",
    "        # self.label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir)\n",
    "        #                          if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))])\n",
    "        # self.label_regions_files = sorted([os.path.join(label_dir_regions, f) for f in os.listdir(label_dir_regions)\n",
    "        #                          if f.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))])\n",
    "\n",
    "        # Verify that we have matching pairs of data and label files\n",
    "        assert len(self.data_files) == len(self.label_files), \"Number of input and label images must match\"\n",
    "\n",
    "        self.indexes = np.arange(len(self.data_files))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # Calculate safe indexes\n",
    "            start_idx = index * self.batch_size\n",
    "            end_idx = min((index + 1) * self.batch_size, len(self.indexes))\n",
    "            batch_indexes = self.indexes[start_idx:end_idx]\n",
    "\n",
    "            # Ensure we don't return empty batches\n",
    "            if len(batch_indexes) == 0:\n",
    "                batch_indexes = self.indexes[-self.batch_size:]  # Take last complete batch\n",
    "\n",
    "            X, y , y_r, filenames_ = self.__data_generation(batch_indexes)\n",
    "\n",
    "            if self.augmentor:\n",
    "                augmented_X = np.empty_like(X)\n",
    "                augmented_y = np.empty_like(y)\n",
    "                for i in range(X.shape[0]):\n",
    "                    img_aug, lbl_aug = self.augmentor.random_transform(X[i].astype('float32'),\n",
    "                                                                     y[i])\n",
    "                    img_aug = self.augmentor.standardize(img_aug)\n",
    "                    augmented_X[i] = img_aug\n",
    "                    augmented_y[i] = lbl_aug\n",
    "                return augmented_X, augmented_y, y_r,  filenames_\n",
    "            else:\n",
    "                # print('batch returned')\n",
    "                return X, y , y_r , filenames_\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, batch_indexes):\n",
    "        X = np.empty((len(batch_indexes), *self.dim, self.n_channels), dtype=np.float32)\n",
    "        y = np.empty((len(batch_indexes), *self.dim, 1), dtype=np.float32)  # Single channel output\n",
    "        y_r= np.empty((len(batch_indexes), *self.dim, 1), dtype=np.float32)\n",
    "\n",
    "        filenames=[]\n",
    "        for i, idx in enumerate(batch_indexes):\n",
    "            filenames.append(self.data_files[idx])\n",
    "            # Load and process input image\n",
    "            img = cv2.imread(self.data_files[idx])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            lbl = cv2.imread(self.label_files[idx])\n",
    "            lbl = cv2.cvtColor(lbl, cv2.COLOR_BGR2GRAY)\n",
    "            # print('img index: ', idx , ' image shape: ', img.shape , lbl.shape)\n",
    "            # print('img values: ',np.min(img), np.max(img ))\n",
    "            lbl2= cv2.imread(self.label_regions_files[idx])\n",
    "            lbl2 = cv2.cvtColor(lbl2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            height, width = img.shape[:2]\n",
    "            # print(self.dim)\n",
    "            if (height, width) != (self.dim[0] , self.dim[1]):\n",
    "                pad_top = (self.target_size - height) // 2\n",
    "                pad_bottom = self.target_size - height - pad_top\n",
    "                pad_left = (self.target_size - width) // 2\n",
    "                pad_right = self.target_size - width - pad_left\n",
    "\n",
    "                img = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=0)\n",
    "                lbl = cv2.copyMakeBorder(lbl, pad_top, pad_bottom, pad_left, pad_right,  borderType=cv2.BORDER_CONSTANT, value=0)\n",
    "                lbl2 = cv2.copyMakeBorder(lbl2, pad_top, pad_bottom, pad_left, pad_right,  borderType=cv2.BORDER_CONSTANT, value=0)\n",
    "            # Process labels\n",
    "            img =img[:, :, np.newaxis]\n",
    "            lbl = lbl[:, :, np.newaxis]\n",
    "            lbl2 = lbl2[:, :, np.newaxis]\n",
    "            # print('lable  values: ' ,np.min(lbl), np.max(lbl) , ' uniq vals: ', np.unique(lbl))\n",
    "\n",
    "            X[i,] = img\n",
    "            y[i,] = lbl\n",
    "            y_r[i,] = lbl2\n",
    "\n",
    "\n",
    "        return  X,y ,y_r , filenames"
   ],
   "id": "b1c4f61fa4671ecc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_batches(generator, n_batches=2):\n",
    "    fig, axes = plt.subplots(n_batches, 3, figsize=(15, 5*n_batches))\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        # Get batch\n",
    "        X_batch, y_batch = generator[i]\n",
    "\n",
    "        # Sample random image from batch\n",
    "        img_idx = np.random.randint(0, X_batch.shape[0])\n",
    "        sample_img = X_batch[img_idx]\n",
    "        sample_mask = y_batch[img_idx]\n",
    "\n",
    "        # Plot\n",
    "        axes[i,0].imshow(sample_img)\n",
    "        axes[i,0].set_title(f'Batch {i+1} Image\\nShape: {sample_img.shape}')\n",
    "        axes[i,0].axis('off')\n",
    "\n",
    "        axes[i,1].imshow(sample_mask.squeeze(), cmap='gray')\n",
    "        axes[i,1].set_title(f'Batch {i+1} Mask\\nMean: {sample_mask.mean():.4f}')\n",
    "        axes[i,1].axis('off')\n",
    "\n",
    "        # Histogram\n",
    "        axes[i,2].hist(sample_img.flatten(), bins=50, alpha=0.7, label='Image')\n",
    "        axes[i,2].hist(sample_mask.flatten(), bins=50, alpha=0.7, label='Mask')\n",
    "        axes[i,2].set_title(f'Batch {i+1} Value Distribution')\n",
    "        axes[i,2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    for i in range(n_batches):\n",
    "        X_batch, y_batch = generator[i]\n",
    "        print(f\"\\nBatch {i+1} Statistics:\")\n",
    "        print(f\"Images - Min: {X_batch.min():.4f}, Max: {X_batch.max():.4f}, Mean: {X_batch.mean():.4f}, Std: {X_batch.std():.4f}\")\n",
    "        print(f\"Masks  - Min: {y_batch.min():.4f}, Max: {y_batch.max():.4f}, Mean: {y_batch.mean():.4f}, Std: {y_batch.std():.4f}\")"
   ],
   "id": "e70eb83b89582111",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def test_batch_consistency(generator, n_test=5):\n",
    "    means_X, means_y = [], []\n",
    "    print(len(generator))\n",
    "    for i in range(min(n_test, len(generator))):\n",
    "        X, y = generator[i]\n",
    "        means_X.append(X.mean())\n",
    "        means_y.append(y.mean())\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(means_X, 'o-')\n",
    "    plt.title('Image Batch Means')\n",
    "    plt.xlabel('Batch Number')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(means_y, 'o-')\n",
    "    plt.title('Mask Batch Means')\n",
    "    plt.xlabel('Batch Number')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image mean variation: {np.std(means_X):.4f}\")\n",
    "    print(f\"Mask mean variation: {np.std(means_y):.4f}\")\n"
   ],
   "id": "94c01511c9c03306",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def detect_cells(density_map, sigma=2, threshold_factor=1.5):\n",
    "    \"\"\"Bulletproof cell detector\"\"\"\n",
    "    # Input validation\n",
    "    if density_map is None:\n",
    "        raise ValueError(\"Input cannot be None\")\n",
    "\n",
    "    # Convert and normalize\n",
    "    density_map = np.array(density_map, dtype=np.float32)\n",
    "    if density_map.ndim == 3:\n",
    "        density_map = density_map.squeeze()\n",
    "\n",
    "    # Normalize if needed\n",
    "    if np.max(density_map) > 1.0:\n",
    "        density_map   /=np.max(density_map)  # Normalize by max value\n",
    "\n",
    "\n",
    "    # Processing\n",
    "    smoothed = gaussian_filter(density_map, sigma=sigma)\n",
    "    threshold = np.mean(smoothed) + threshold_factor * np.std(smoothed)\n",
    "    coords = peak_local_max(smoothed, min_distance=2, threshold_abs=threshold)\n",
    "\n",
    "    return [(int(x), int(y)) for y, x in coords]\n"
   ],
   "id": "800732d984b595fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize_to_uint8(image):\n",
    "        if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "            image = np.clip(image, 0, 1)  # Ensure range [0, 1]\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        return image"
   ],
   "id": "aef65762173db6e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def save_sample(img, label , gt,  folder_name , sample_file_name, lable_type ,saved_cell_counts, gt_cell_counts , predict_cell_counts):\n",
    "    folder_name = folder_name + str(sample_file_name)+ \"/\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    # print('image size is :', folder_name , img.shape , label.shape , gt.shape)\n",
    "    output_path = os.path.join(folder_name, 'counts.txt')\n",
    "    with open(output_path, 'a') as file:\n",
    "        # file.write('ground truth cell counts : '+str(gt_cell_counts) + '\\n')\n",
    "        # file.write('predicted cell counts : '+str(predict_cell_counts) + '\\n')\n",
    "        file.write(f'saved auto cell counts:{str(saved_cell_counts)}\\n')\n",
    "        file.write(f'Ground Truth Cells: {str(gt_cell_counts)}\\n')\n",
    "        file.write(f'Predicted Cells {str(lable_type)} : {str(predict_cell_counts)}\\n\\n\\n')\n",
    "\n",
    "    # squeezed_label =  np.squeeze(label)\n",
    "    # squeezed_gt =  np.squeeze(gt)\n",
    "\n",
    "    img = normalize_to_uint8(img)\n",
    "    # squeezed_label = normalize_to_uint8(squeezed_label)\n",
    "    # squeezed_gt = normalize_to_uint8(squeezed_gt)\n",
    "\n",
    "\n",
    "    # # Ensure images are in the correct range\n",
    "    # if img.dtype == np.float64 or img.dtype == np.float32:\n",
    "    #     img = np.interp(img, (img.min(), img.max()), (0, 1))\n",
    "    #\n",
    "    # if squeezed_label.dtype == np.float64 or squeezed_label.dtype == np.float32:\n",
    "    #     squeezed_label = np.interp(squeezed_label, (squeezed_label.min(), squeezed_label.max()), (0, 1))\n",
    "    # if squeezed_gt.dtype == np.float64 or squeezed_gt.dtype == np.float32:\n",
    "    #     squeezed_gt = np.interp(squeezed_gt, (squeezed_gt.min(), squeezed_gt.max()), (0, 1))\n",
    "\n",
    "    print('image size is : ',img.shape)\n",
    "    # Save images using OpenCV (preserves exact dimensions)\n",
    "    cv2.imwrite(os.path.join(folder_name, 'image_1.jpg'), img)\n",
    "    cv2.imwrite(os.path.join(folder_name, f'image_pr_{lable_type}.jpg'), (label * 255).astype(np.uint8))\n",
    "    cv2.imwrite(os.path.join(folder_name, f'image_gt_{lable_type}.jpg'), (gt * 255).astype(np.uint8))\n",
    "\n",
    "    #  Calculate figure size in inches (512 pixels / dpi)\n",
    "    # dpi = 100  # Default is 100, but you can adjust\n",
    "    # height, width = img.shape[0], img.shape[1]\n",
    "    #\n",
    "    # figsize = (width / dpi, height / dpi)\n",
    "    #\n",
    "    # # Save img\n",
    "    # fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    # ax.imshow(img)\n",
    "    # # ax.set_title('Image')\n",
    "    # plt.axis('off')  # Turn off the axis\n",
    "    # output_path = os.path.join(folder_name, 'image_1.jpg')\n",
    "    # plt.savefig(output_path, bbox_inches='tight', pad_inches=0)  # Save without white spaces\n",
    "    # plt.close(fig)  # Close the figure to free up memory\n",
    "    # print(img.shape)\n",
    "    #\n",
    "    # # Save the third image\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(squeezed_label)\n",
    "    # # ax.set_title('Squeezed Label')\n",
    "    # plt.axis('off')  # Turn off the axis\n",
    "    # output_path = os.path.join(folder_name, 'image_pr_'+lable_type+'.jpg')\n",
    "    # plt.savefig(output_path, bbox_inches='tight', pad_inches=0)  # Save without white spaces\n",
    "    # plt.close(fig)  # Close the figure to free up memory\n",
    "    #\n",
    "    #  # Save the third image\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(squeezed_gt)\n",
    "    # # ax.set_title('Squeezed gt')\n",
    "    # plt.axis('off')  # Turn off the axis\n",
    "    # output_path = os.path.join(folder_name, 'image_gt_'+lable_type+'.jpg')\n",
    "    # plt.savefig(output_path, bbox_inches='tight', pad_inches=0)  # Save without white spaces\n",
    "    # plt.close(fig)  # Close the figure to free up memory\n",
    "    # plt.show()"
   ],
   "id": "f562eed5d40c163f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_save_all_sample(img , c_label , c_gt , folder_name , sample_file_name , saved_cell_counts , gt_counts  , predict_cell_counts , labletype):\n",
    "\n",
    "    squeezed_c_label = np.squeeze(c_label)\n",
    "    # Ensure images are in the correct range\n",
    "    if img.dtype == np.float64 or img.dtype == np.float32:\n",
    "        img = np.interp(img, (img.min(), img.max()), (0, 1))\n",
    "\n",
    "    if squeezed_c_label.dtype == np.float64 or squeezed_c_label.dtype == np.float32:\n",
    "        squeezed_c_label = np.interp(squeezed_c_label, (squeezed_c_label.min(), squeezed_c_label.max()), (0, 1))\n",
    "\n",
    "    # figure, axis = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    # axis[0].imshow(img)\n",
    "    # axis[0].set_title('Image')\n",
    "    # axis[0].axis('off')\n",
    "    #\n",
    "    #\n",
    "    # axis[1].imshow(c_gt)\n",
    "    # axis[1].set_title('Centroids Ground Truth')\n",
    "    # axis[1].axis('off')\n",
    "    #\n",
    "    # axis[2].imshow(squeezed_c_label)\n",
    "    # axis[2].set_title('Centroids Prediction')\n",
    "    # axis[2].axis('off')\n",
    "    # plt.show()\n",
    "    save_sample(img, squeezed_c_label ,c_gt, folder_name , sample_file_name, labletype ,saved_cell_counts,  gt_counts , predict_cell_counts  )"
   ],
   "id": "9592bb1bd9dd89ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting Light-U-Net Predictions",
   "id": "74e1d65b17397f1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_regions = buildModel_Light_U_net(input_dim = (256,256,1))\n",
    "\n",
    "model_regions.load_weights('./checkpoints/Light_U_Net_regions_256_20250921-013403.hdf5')\n"
   ],
   "id": "ce4a201e00500e22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Train & Test set",
   "id": "fca8a997f6d87572"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_address= './Dataset/'\n",
    "train_img_path = base_address + 'train/dic_tiles_256/'\n",
    "train_centroids_img_path = base_address + 'train/gt_tiles_256/'\n",
    "train_regions_img_path = base_address + 'train/regions_tiles/'\n",
    "\n",
    "test_img_path = base_address + 'test/dic_tiles_256/'\n",
    "test_centroids_img_path = base_address + 'test/gt_tiles_256/'\n",
    "test_regions_img_path = base_address + 'test/regions_tiles_256/'\n",
    "\n",
    "train_generator = CustomDataGenerator(\n",
    "    data_dir=train_img_path,\n",
    "    label_dir=train_centroids_img_path,\n",
    "    label_dir_regions= train_regions_img_path,\n",
    "    batch_size=4,\n",
    "    dim=(256, 256),  # Target size\n",
    "    n_channels=1,     # Grayscale\n",
    "    shuffle=True,\n",
    "    augmentor=None  # Optional\n",
    ")\n",
    "test_generator = CustomDataGenerator(\n",
    "    data_dir=test_img_path,\n",
    "    label_dir=test_centroids_img_path,\n",
    "    label_dir_regions= test_regions_img_path,\n",
    "    batch_size=4,\n",
    "    dim=(256, 256),  # Target size\n",
    "    n_channels=1,     # Grayscale\n",
    "    shuffle=True,\n",
    "    augmentor=None  # Optional\n",
    ")\n",
    "print('train batch length: ' , len(train_generator) , 'test batch length: ' , len(test_generator))\n"
   ],
   "id": "1ece8836a2100be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_name= './results/Light_U_Net/train_outputs_light_u_net_256/'\n",
    "# os.makedirs(folder_name)\n",
    "# saved_files= os.listdir(folder_name)\n",
    "# print('sample: ', saved_files[0])\n",
    "\n",
    "for i in range(max (1 , len(train_generator))):\n",
    "    tr_X, tr_y ,tr_y_r, tr_filenames  = train_generator[i]\n",
    "    print(tr_filenames)\n",
    "    # te_X_, te_y_  ,te_y_r, te_filenames = test_generator[i]\n",
    "    # print('train_gen data shape: ' ,tr_X.shape , tr_y.shape , 'label img min, mean, max : ', np.min(tr_y[0]) , np.mean(tr_y[0]), np.max(tr_y[0]))\n",
    "    # print('test_gen data shape: ' ,te_X_.shape , te_y_.shape , 'label min, mean, max : ', np.min(te_y_[0]) , np.mean(te_y_[0]), np.max(te_y_[0]))\n",
    "\n",
    "    pr_tr_x_r = model_regions.predict(tr_X)\n",
    "\n",
    "    for i in range( max (1, tr_X.shape[0])):\n",
    "\n",
    "        if pr_tr_x_r[i] is None:\n",
    "            raise ValueError(\"Input density_map cannot be None\")\n",
    "\n",
    "        gt_cell_centroids = detect_cells(tr_y[i], sigma=2, threshold_factor=1.5)\n",
    "        predict_cell_counts=  detect_cells(pr_tr_x_r[i], sigma=2.5, threshold_factor=1.5)\n",
    "        # print(\"saved cell counts: \" ,cell_counts[i] , \"cell counts in gt: \" , len(gt_cell_centroids), \"cell counts in prediction: \", len(predict_cell_counts))\n",
    "\n",
    "        show_save_all_sample(tr_X[i] , pr_tr_x_r[i], tr_y_r[i] , folder_name , tr_filenames[i].split('/')[-1] ,len(gt_cell_centroids) , len(gt_cell_centroids) , len(predict_cell_counts) ,'regions' )\n",
    "        print(\"sample \",  tr_filenames[i].split('/')[-1] , \" saved\")\n",
    "        # break"
   ],
   "id": "69400b77d819e48d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Eval set",
   "id": "83b62328231fec66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_address= './Dataset/'\n",
    "eval_img_path = base_address + 'eval/dic_tiles_256/'\n",
    "\n",
    "eval_generator = CustomDataGenerator(\n",
    "    data_dir=eval_img_path,\n",
    "    label_dir=eval_img_path,\n",
    "    label_dir_regions= eval_img_path,\n",
    "    batch_size=4,\n",
    "    dim=(256, 256),  # Target size\n",
    "    n_channels=1,     # Grayscale\n",
    "    shuffle=True,\n",
    "    augmentor=None  # Optional\n",
    ")\n",
    "\n",
    "print('eval batch length: ' , len(eval_generator))\n"
   ],
   "id": "7f9e61d86b5bb48c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_name= './results/Light_U_Net/eval_outputs_light_u_net_256/'\n",
    "# os.makedirs(folder_name)\n",
    "# saved_files= os.listdir(folder_name)\n",
    "# print('sample: ', saved_files[0])\n",
    "\n",
    "for i in range(max (1 , len(eval_generator))):\n",
    "    tr_X, tr_y ,tr_y_r, tr_filenames  = eval_generator[i]\n",
    "    print(tr_filenames)\n",
    "    # te_X_, te_y_  ,te_y_r, te_filenames = test_generator[i]\n",
    "    # print('train_gen data shape: ' ,tr_X.shape , tr_y.shape , 'label img min, mean, max : ', np.min(tr_y[0]) , np.mean(tr_y[0]), np.max(tr_y[0]))\n",
    "    # print('test_gen data shape: ' ,te_X_.shape , te_y_.shape , 'label min, mean, max : ', np.min(te_y_[0]) , np.mean(te_y_[0]), np.max(te_y_[0]))\n",
    "\n",
    "    pr_tr_x_r = model_regions.predict(tr_X)\n",
    "\n",
    "    for i in range( max (1, tr_X.shape[0])):\n",
    "\n",
    "        if pr_tr_x_r[i] is None:\n",
    "            raise ValueError(\"Input density_map cannot be None\")\n",
    "        gt_cell_centroids = detect_cells(tr_y[i], sigma=2, threshold_factor=1.5)\n",
    "        predict_cell_counts=  detect_cells(pr_tr_x_r[i], sigma=2.5, threshold_factor=1.5)\n",
    "        # print(\"saved cell counts: \" ,cell_counts[i] , \"cell counts in gt: \" , len(gt_cell_centroids), \"cell counts in prediction: \", len(predict_cell_counts))\n",
    "\n",
    "        show_save_all_sample(tr_X[i] , pr_tr_x_r[i], tr_y_r[i] , folder_name , tr_filenames[i].split('/')[-1] ,len(gt_cell_centroids) , len(gt_cell_centroids) , len(predict_cell_counts) ,'regions' )\n",
    "        print(\"sample \",  tr_filenames[i].split('/')[-1] , \" saved\")\n",
    "        # break"
   ],
   "id": "187c932f436a49ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting U-Net Predictions",
   "id": "6bcbddccbf6ae924"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_regions = build_unet_model(input_dim = (256,256,1))\n",
    "\n",
    "model_regions.load_weights('./checkpoints/U_Net_regions_20250908-155828.hdf5')\n"
   ],
   "id": "e982b59ef5864de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Train & Test set",
   "id": "3066ac5e43a46b8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_address= './Dataset/'\n",
    "train_img_path = base_address + 'train/dic_tiles_256/'\n",
    "train_centroids_img_path = base_address + 'train/gt_tiles_256/'\n",
    "train_regions_img_path = base_address + 'train/regions_tiles_256/'\n",
    "\n",
    "test_img_path = base_address + 'test/dic_tiles_256/'\n",
    "test_centroids_img_path = base_address + 'test/gt_tiles_256/'\n",
    "test_regions_img_path = base_address + 'test/regions_tiles_256/'\n",
    "\n",
    "train_generator = CustomDataGenerator(\n",
    "    data_dir=train_img_path,\n",
    "    label_dir=train_centroids_img_path,\n",
    "    label_dir_regions= train_regions_img_path,\n",
    "    batch_size=4,\n",
    "    dim=(256, 256),  # Target size\n",
    "    n_channels=1,     # Grayscale\n",
    "    shuffle=True,\n",
    "    augmentor=None  # Optional\n",
    ")\n",
    "test_generator = CustomDataGenerator(\n",
    "    data_dir=test_img_path,\n",
    "    label_dir=test_centroids_img_path,\n",
    "    label_dir_regions= test_regions_img_path,\n",
    "    batch_size=4,\n",
    "    dim=(256, 256),  # Target size\n",
    "    n_channels=1,     # Grayscale\n",
    "    shuffle=True,\n",
    "    augmentor=None  # Optional\n",
    ")\n",
    "print('train batch length: ' , len(train_generator) , 'test batch length: ' , len(test_generator))\n",
    "\n"
   ],
   "id": "8936ecddd189e159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "folder_name= './results/U_Net/train_outputs_u_net_256/'\n",
    "# os.makedirs(folder_name)\n",
    "# saved_files= os.listdir(folder_name)\n",
    "# print('sample: ', saved_files[0])\n",
    "\n",
    "for i in range(len(train_generator)):\n",
    "    tr_X, tr_y ,tr_y_r, tr_filenames  = train_generator[i]\n",
    "    # te_X_, te_y_  ,te_y_r, te_filenames = test_generator[i]\n",
    "    print('test_gen data shape: ' ,tr_X.shape , tr_y.shape , 'label img min, mean, max : ', np.min(tr_y[0]) , np.mean(tr_y[0]), np.max(tr_y[0]))\n",
    "\n",
    "    pr_tr_x_r = model_regions.predict(tr_X)\n",
    "\n",
    "\n",
    "    for i in range( tr_X.shape[0]):\n",
    "        # filename = counter* batch_size + i\n",
    "        # if pr_tr_x_r[i] is None:\n",
    "        #     raise ValueError(\"Input density_map cannot be None\")\n",
    "\n",
    "        if pr_tr_x_r[i] is None:\n",
    "            raise ValueError(\"Input density_map cannot be None\")\n",
    "        gt_cell_centroids = detect_cells(tr_y[i], sigma=2, threshold_factor=1.5)\n",
    "        predict_cell_counts=  detect_cells(pr_tr_x_r[i], sigma=2, threshold_factor=1)\n",
    "        # print(\"saved cell counts: \" ,cell_counts[i] , \"cell counts in gt: \" , len(gt_cell_centroids), \"cell counts in prediction: \", len(predict_cell_counts))\n",
    "\n",
    "        show_save_all_sample(tr_X[i] , pr_tr_x_r[i], tr_y_r[i] , folder_name , tr_filenames[i].split('/')[-1] ,len(gt_cell_centroids) , len(gt_cell_centroids) , len(predict_cell_counts) ,'regions' )\n",
    "        print(\"sample \",  tr_filenames[i].split('/')[-1] , \" saved\")\n",
    "\n",
    "    # break"
   ],
   "id": "6beb66dd869da3d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting Eval set\n",
   "id": "cd53ef8a28d30785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_name= './results/U_Net/eval_outputs_u_net_256/'\n",
    "\n",
    "\n",
    "for i in range(len(eval_generator)):\n",
    "    tr_X, tr_y ,tr_y_r, tr_filenames  = eval_generator[i]\n",
    "    # te_X_, te_y_  ,te_y_r, te_filenames = test_generator[i]\n",
    "    print('test_gen data shape: ' ,tr_X.shape , tr_y.shape , 'label img min, mean, max : ', np.min(tr_y[0]) , np.mean(tr_y[0]), np.max(tr_y[0]))\n",
    "\n",
    "    pr_tr_x_r = model_regions.predict(tr_X)\n",
    "\n",
    "\n",
    "    for i in range( tr_X.shape[0]):\n",
    "\n",
    "        if pr_tr_x_r[i] is None:\n",
    "            raise ValueError(\"Input density_map cannot be None\")\n",
    "        gt_cell_centroids = detect_cells(tr_y[i], sigma=2, threshold_factor=1.5)\n",
    "        predict_cell_counts=  detect_cells(pr_tr_x_r[i], sigma=2, threshold_factor=1)\n",
    "        # print(\"saved cell counts: \" ,cell_counts[i] , \"cell counts in gt: \" , len(gt_cell_centroids), \"cell counts in prediction: \", len(predict_cell_counts))\n",
    "\n",
    "        show_save_all_sample(tr_X[i] , pr_tr_x_r[i], tr_y_r[i] , folder_name , tr_filenames[i].split('/')[-1] ,len(gt_cell_centroids) , len(gt_cell_centroids) , len(predict_cell_counts) ,'regions' )\n",
    "        print(\"sample \",  tr_filenames[i].split('/')[-1] , \" saved\")\n",
    "\n",
    "    # break"
   ],
   "id": "490d84a2ec577330",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
